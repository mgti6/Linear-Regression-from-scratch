# ğŸ§  Linear Regression from Scratch â€” A Comparative Approach

ğŸ“Œ Description
This project implements Linear Regression from scratch using Gradient Descent and compares the results with Scikit-learn's LinearRegression and SGDRegressor.
It aims to demonstrate how linear regression works under the hood, how gradient descent optimizes parameters, and how it compares to modern machine learning libraries.

ğŸ“Š What This Project Covers
ğŸ’¡ Understanding the concept of Mean Squared Error (MSE) as a cost function
â›°ï¸ Implementing Gradient Descent with the mountain analogy
ğŸ“ˆ Visualizing the fitted line on synthetic data
ğŸ” Comparing custom implementation with:
LinearRegression (closed-form)
SGDRegressor (gradient descent)
ğŸ“‰ Evaluating and comparing loss (MSE) between models

ğŸ“ Files
linear_regression_scratch.ipynb â€” Main notebook with code, explanations and comparisons
README.md â€” You're here!

âš™ï¸ Technologies Used
Python 3
NumPy
Pandas
Matplotlib 
Scikit-learn

ğŸ“Œ Sample Output
Comparison of model coefficients
Graphs showing fitted lines and convergence
MSE values for each method

âœï¸ Author
### âœï¸ Author
**Nicolas Morganti**  
  Master's student in Applied Probabilities and Statistics  
  Passionate about machine learning, finance, and data science  
  ğŸ”— [LinkedIn Profile](https://www.linkedin.com/in/nicolas-morganti)
